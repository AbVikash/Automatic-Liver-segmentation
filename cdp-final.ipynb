{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **CDP Automatic Liver & Tumor segmentation** "]},{"cell_type":"markdown","metadata":{},"source":["# **1- Imports**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:27:17.812880Z","iopub.status.busy":"2023-11-20T05:27:17.812128Z","iopub.status.idle":"2023-11-20T05:27:17.820829Z","shell.execute_reply":"2023-11-20T05:27:17.819756Z","shell.execute_reply.started":"2023-11-20T05:27:17.812844Z"},"trusted":true},"outputs":[],"source":["import os\n","import glob\n","import cv2\n","import imageio\n","\n","import numpy as np \n","import pandas as pd \n","import nibabel as nib\n","import matplotlib.pyplot as plt\n","\n","from tqdm.notebook import tqdm\n","from ipywidgets import *\n","from PIL import Image\n","from matplotlib.pyplot import figure\n","\n","from fastai.basics import *\n","from fastai.vision.all import *\n","from fastai.data.transforms import *"]},{"cell_type":"markdown","metadata":{},"source":["# **2- Data Preparation**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:27:14.910277Z","iopub.status.busy":"2023-11-20T05:27:14.909855Z","iopub.status.idle":"2023-11-20T05:27:14.975886Z","shell.execute_reply":"2023-11-20T05:27:14.974971Z","shell.execute_reply.started":"2023-11-20T05:27:14.910231Z"},"trusted":true},"outputs":[],"source":["# Create a meta file for nii files processing\n","\n","file_list = []\n","for dirname, _, filenames in os.walk('../input/liver-tumor-segmentation'):\n","    for filename in filenames:\n","        file_list.append((dirname, filename)) \n","\n","for dirname, _, filenames in os.walk('../input/liver-tumor-segmentation-part-2'):\n","    for filename in filenames:\n","        file_list.append((dirname, filename)) \n","\n","df_files = pd.DataFrame(file_list, columns =['dirname', 'filename']) \n","df_files.sort_values(by=['filename'], ascending=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:27:23.272283Z","iopub.status.busy":"2023-11-20T05:27:23.271464Z","iopub.status.idle":"2023-11-20T05:27:23.378413Z","shell.execute_reply":"2023-11-20T05:27:23.377403Z","shell.execute_reply.started":"2023-11-20T05:27:23.272248Z"},"trusted":true},"outputs":[],"source":["# Map CT scan and label \n","\n","df_files[\"mask_dirname\"]  = \"\"\n","df_files[\"mask_filename\"] = \"\"\n","\n","for i in range(131):\n","    ct = f\"volume-{i}.nii\"\n","    mask = f\"segmentation-{i}.nii\"\n","    \n","    df_files.loc[df_files['filename'] == ct, 'mask_filename'] = mask\n","    df_files.loc[df_files['filename'] == ct, 'mask_dirname'] = \"../input/liver-tumor-segmentation/segmentations\"\n","\n","# drop segment rows\n","df_files = df_files[df_files.mask_filename != ''].sort_values(by=['filename']).reset_index(drop=True) \n","\n","df_files"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:27:26.219245Z","iopub.status.busy":"2023-11-20T05:27:26.218196Z","iopub.status.idle":"2023-11-20T05:27:26.225382Z","shell.execute_reply":"2023-11-20T05:27:26.224331Z","shell.execute_reply.started":"2023-11-20T05:27:26.219199Z"},"trusted":true},"outputs":[],"source":["def read_nii(filepath):\n","    '''\n","    Reads .nii file and returns pixel array\n","    '''\n","    ct_scan = nib.load(filepath)\n","    array   = ct_scan.get_fdata()\n","    array   = np.rot90(np.array(array))\n","    return(array)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:27:29.355783Z","iopub.status.busy":"2023-11-20T05:27:29.355048Z","iopub.status.idle":"2023-11-20T05:27:29.578395Z","shell.execute_reply":"2023-11-20T05:27:29.577425Z","shell.execute_reply.started":"2023-11-20T05:27:29.355749Z"},"trusted":true},"outputs":[],"source":["# Read sample\n","\n","sample = 0\n","sample_ct = read_nii(df_files.loc[sample,'dirname']+\"/\"+df_files.loc[sample,'filename'])\n","sample_mask = read_nii(df_files.loc[sample,'mask_dirname']+\"/\"+df_files.loc[sample,'mask_filename'])\n","\n","print(f'CT Shape:   {sample_ct.shape}\\nMask Shape: {sample_mask.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:27:32.379081Z","iopub.status.busy":"2023-11-20T05:27:32.378228Z","iopub.status.idle":"2023-11-20T05:27:32.463582Z","shell.execute_reply":"2023-11-20T05:27:32.462596Z","shell.execute_reply.started":"2023-11-20T05:27:32.379048Z"},"trusted":true},"outputs":[],"source":["print(np.amin(sample_ct), np.amax(sample_ct))\n","print(np.amin(sample_mask), np.amax(sample_mask))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:27:34.902471Z","iopub.status.busy":"2023-11-20T05:27:34.902067Z","iopub.status.idle":"2023-11-20T05:27:35.556332Z","shell.execute_reply":"2023-11-20T05:27:35.555314Z","shell.execute_reply.started":"2023-11-20T05:27:34.902439Z"},"trusted":true},"outputs":[],"source":["# Preprocess the nii file \n","# Source https://docs.fast.ai/medical.imaging\n","\n","dicom_windows = types.SimpleNamespace(\n","    brain=(80,40),\n","    subdural=(254,100),\n","    stroke=(8,32),\n","    brain_bone=(2800,600),\n","    brain_soft=(375,40),\n","    lungs=(1500,-600),\n","    mediastinum=(350,50),\n","    abdomen_soft=(400,50),\n","    liver=(150,30),\n","    spine_soft=(250,50),\n","    spine_bone=(1800,400),\n","    custom = (200,60)\n",")\n","\n","@patch\n","def windowed(self:Tensor, w, l):\n","    px = self.clone()\n","    px_min = l - w//2\n","    px_max = l + w//2\n","    px[px<px_min] = px_min\n","    px[px>px_max] = px_max\n","    return (px-px_min) / (px_max-px_min)\n","\n","figure(figsize=(8, 6), dpi=100)\n","\n","plt.imshow(tensor(sample_ct[..., 55].astype(np.float32)).windowed(*dicom_windows.liver), cmap=plt.cm.bone);"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:27:41.007591Z","iopub.status.busy":"2023-11-20T05:27:41.007154Z","iopub.status.idle":"2023-11-20T05:27:41.019050Z","shell.execute_reply":"2023-11-20T05:27:41.017844Z","shell.execute_reply.started":"2023-11-20T05:27:41.007556Z"},"trusted":true},"outputs":[],"source":["def plot_sample(array_list, color_map = 'nipy_spectral'):\n","    '''\n","    Plots and a slice with all available annotations\n","    '''\n","    fig = plt.figure(figsize=(20,16), dpi=100)\n","\n","    plt.subplot(1,4,1)\n","    plt.imshow(array_list[0], cmap='bone')\n","    plt.title('Original Image')\n","    plt.axis('off')\n","    \n","    plt.subplot(1,4,2)\n","    plt.imshow(tensor(array_list[0].astype(np.float32)).windowed(*dicom_windows.liver), cmap='bone');\n","    plt.title('Windowed Image')\n","    plt.axis('off')\n","             \n","    plt.subplot(1,4,3)\n","    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n","    plt.title('Mask')\n","    plt.axis('off')\n","    \n","    plt.subplot(1,4,4)\n","    plt.imshow(array_list[0], cmap='bone')\n","    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n","    plt.title('Liver & Mask')\n","    plt.axis('off')\n","    \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:27:44.837183Z","iopub.status.busy":"2023-11-20T05:27:44.836800Z","iopub.status.idle":"2023-11-20T05:27:45.464283Z","shell.execute_reply":"2023-11-20T05:27:45.463345Z","shell.execute_reply.started":"2023-11-20T05:27:44.837150Z"},"trusted":true},"outputs":[],"source":["sample = 55\n","\n","sample_slice = tensor(sample_ct[...,sample].astype(np.float32))\n","\n","plot_sample([sample_ct[..., sample],\n","             sample_mask[..., sample]])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:27:51.416685Z","iopub.status.busy":"2023-11-20T05:27:51.415690Z","iopub.status.idle":"2023-11-20T05:27:51.427182Z","shell.execute_reply":"2023-11-20T05:27:51.426023Z","shell.execute_reply.started":"2023-11-20T05:27:51.416650Z"},"trusted":true},"outputs":[],"source":["# Check the mask values\n","mask = Image.fromarray(sample_mask[...,sample].astype('uint8'), mode=\"L\")\n","unique, counts = np.unique(mask, return_counts=True)\n","print(np.array((unique, counts)).T)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:27:58.956218Z","iopub.status.busy":"2023-11-20T05:27:58.955353Z","iopub.status.idle":"2023-11-20T05:27:59.188456Z","shell.execute_reply":"2023-11-20T05:27:59.187115Z","shell.execute_reply.started":"2023-11-20T05:27:58.956177Z"},"trusted":true},"outputs":[],"source":["# Preprocessing functions\n","# Source https://docs.fast.ai/medical.imaging\n","\n","class TensorCTScan(TensorImageBW): _show_args = {'cmap':'bone'}\n","\n","@patch\n","def freqhist_bins(self:Tensor, n_bins=100):\n","    \"A function to split the range of pixel values into groups, such that each group has around the same number of pixels\"\n","    imsd = self.view(-1).sort()[0]\n","    t = torch.cat([tensor([0.001]),\n","                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n","                   tensor([0.999])])\n","    t = (len(imsd)*t).long()\n","    return imsd[t].unique()\n","    \n","@patch\n","def hist_scaled(self:Tensor, brks=None):\n","    \"Scales a tensor using `freqhist_bins` to values between 0 and 1\"\n","    if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n","    if brks is None: brks = self.freqhist_bins()\n","    ys = np.linspace(0., 1., len(brks))\n","    x = self.numpy().flatten()\n","    x = np.interp(x, brks.numpy(), ys)\n","    return tensor(x).reshape(self.shape).clamp(0.,1.)\n","    \n","    \n","@patch\n","def to_nchan(x:Tensor, wins, bins=None):\n","    res = [x.windowed(*win) for win in wins]\n","    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))\n","    dim = [0,1][x.dim()==3]\n","    return TensorCTScan(torch.stack(res, dim=dim))\n","\n","@patch\n","def save_jpg(x:(Tensor), path, wins, bins=None, quality=120):\n","    fn = Path(path).with_suffix('.jpg')\n","    x = (x.to_nchan(wins, bins)*255).byte()\n","    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])\n","    im.save(fn, quality=quality)\n","\n","_,axs = subplots(1,1)\n","\n","sample_slice.save_jpg('test.jpg', [dicom_windows.liver, dicom_windows.custom])\n","show_image(Image.open('test.jpg'), ax=axs[0], figsize=(8, 6))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T04:09:38.332121Z","iopub.status.busy":"2023-11-20T04:09:38.331745Z","iopub.status.idle":"2023-11-20T04:21:09.360704Z","shell.execute_reply":"2023-11-20T04:21:09.359512Z","shell.execute_reply.started":"2023-11-20T04:09:38.332093Z"},"trusted":true},"outputs":[],"source":["# Make custom JPG files for Unet training\n","# Total number of 131 nii files contains 67072 slices \n","\n","GENERATE_JPG_FILES = True\n","\n","if (GENERATE_JPG_FILES) :\n","    \n","    path = Path(\".\")\n","\n","    os.makedirs('train_images',exist_ok=True)\n","    os.makedirs('train_masks',exist_ok=True)\n","\n","    for ii in tqdm(range(0,len(df_files),3)): # take 1/3 nii files for training\n","        curr_ct        = read_nii(df_files.loc[ii,'dirname']+\"/\"+df_files.loc[ii,'filename'])\n","        curr_mask      = read_nii(df_files.loc[ii,'mask_dirname']+\"/\"+df_files.loc[ii,'mask_filename'])\n","        curr_file_name = str(df_files.loc[ii,'filename']).split('.')[0]\n","        curr_dim       = curr_ct.shape[2] # 512, 512, curr_dim\n","\n","        for curr_slice in range(0,curr_dim,2): # export every 2nd slice for training\n","            data = tensor(curr_ct[...,curr_slice].astype(np.float32))\n","            mask = Image.fromarray(curr_mask[...,curr_slice].astype('uint8'), mode=\"L\")\n","            data.save_jpg(f\"train_images/{curr_file_name}_slice_{curr_slice}.jpg\", [dicom_windows.liver,dicom_windows.custom])\n","            mask.save(f\"train_masks/{curr_file_name}_slice_{curr_slice}_mask.png\")\n","else:\n","    path = Path(\"../input/liver-segmentation-with-fastai-v2\") # read jpg from saved kernel output"]},{"cell_type":"markdown","metadata":{},"source":["# **3- Model Training**\n","### We used the U-Net model with ResNet-50 as backbone architecture from [ResNet](https://arxiv.org/pdf/1512.03385.pdf)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:28:22.919948Z","iopub.status.busy":"2023-11-20T05:28:22.919551Z","iopub.status.idle":"2023-11-20T05:28:23.039193Z","shell.execute_reply":"2023-11-20T05:28:23.038266Z","shell.execute_reply.started":"2023-11-20T05:28:22.919915Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 16\n","IMAGE_SIZE = 128\n","\n","codes = np.array([\"background\",\"liver\",\"tumor\"])\n","    \n","def get_x(fname:Path): return fname\n","def label_func(x): return path/'train_masks'/f'{x.stem}_mask.png'\n","\n","tfms = [IntToFloatTensor(),Normalize()]\n","\n","db = DataBlock(blocks=(ImageBlock(),MaskBlock(codes)),  #codes = {\"Backround\": 0,\"Liver\": 1,\"Tumor\": 2}\n","               batch_tfms=tfms,\n","               splitter=RandomSplitter(),\n","               item_tfms=[Resize(IMAGE_SIZE)],\n","               get_items=get_image_files,\n","               get_y=label_func)\n","\n","ds = db.datasets(source=path/'train_images')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:28:26.138824Z","iopub.status.busy":"2023-11-20T05:28:26.137950Z","iopub.status.idle":"2023-11-20T05:28:26.405628Z","shell.execute_reply":"2023-11-20T05:28:26.404298Z","shell.execute_reply.started":"2023-11-20T05:28:26.138785Z"},"trusted":true},"outputs":[],"source":["idx = 20\n","imgs = [ds[idx][0],ds[idx][1]]\n","fig, axs = plt.subplots(1, 2)\n","\n","for i,ax in enumerate(axs.flatten()):\n","    ax.axis('off')\n","    ax.imshow(imgs[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:28:30.038688Z","iopub.status.busy":"2023-11-20T05:28:30.038248Z","iopub.status.idle":"2023-11-20T05:28:30.060068Z","shell.execute_reply":"2023-11-20T05:28:30.059067Z","shell.execute_reply.started":"2023-11-20T05:28:30.038653Z"},"trusted":true},"outputs":[],"source":["unique, counts = np.unique(array(ds[idx][1]), return_counts=True)\n","\n","print( np.array((unique, counts)).T)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:28:43.717684Z","iopub.status.busy":"2023-11-20T05:28:43.716904Z","iopub.status.idle":"2023-11-20T05:28:45.017554Z","shell.execute_reply":"2023-11-20T05:28:45.016494Z","shell.execute_reply.started":"2023-11-20T05:28:43.717649Z"},"trusted":true},"outputs":[],"source":["dls = db.dataloaders(path/'train_images', bs = BATCH_SIZE) #, num_workers=0\n","dls.show_batch()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:29:04.711145Z","iopub.status.busy":"2023-11-20T05:29:04.710143Z","iopub.status.idle":"2023-11-20T05:29:04.719095Z","shell.execute_reply":"2023-11-20T05:29:04.718024Z","shell.execute_reply.started":"2023-11-20T05:29:04.711102Z"},"trusted":true},"outputs":[],"source":["def foreground_acc(inp, targ, bkg_idx=0, axis=1):  # exclude a background from metric\n","    \"Computes non-background accuracy for multiclass segmentation\"\n","    targ = targ.squeeze(1)\n","    mask = targ != bkg_idx\n","    return (inp.argmax(dim=axis)[mask]==targ[mask]).float().mean() \n","\n","def cust_foreground_acc(inp, targ):  # # include a background into the metric\n","    return foreground_acc(inp=inp, targ=targ, bkg_idx=3, axis=1) # 3 is a dummy value to include the background which is 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T04:23:29.272405Z","iopub.status.busy":"2023-11-20T04:23:29.272012Z","iopub.status.idle":"2023-11-20T04:23:39.509464Z","shell.execute_reply":"2023-11-20T04:23:39.508412Z","shell.execute_reply.started":"2023-11-20T04:23:29.272371Z"},"trusted":true},"outputs":[],"source":["learn = unet_learner(dls,\n","                     resnet50,\n","                     loss_func=CrossEntropyLossFlat(axis=1),\n","                     metrics=[foreground_acc, cust_foreground_acc]) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T04:23:39.511507Z","iopub.status.busy":"2023-11-20T04:23:39.511172Z","iopub.status.idle":"2023-11-20T05:00:10.435314Z","shell.execute_reply":"2023-11-20T05:00:10.434146Z","shell.execute_reply.started":"2023-11-20T04:23:39.511481Z"},"trusted":true},"outputs":[],"source":["learn.fine_tune(5, wd=0.1, cbs=SaveModelCallback() )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:29:18.375353Z","iopub.status.busy":"2023-11-20T05:29:18.374565Z","iopub.status.idle":"2023-11-20T05:29:20.294794Z","shell.execute_reply":"2023-11-20T05:29:20.293499Z","shell.execute_reply.started":"2023-11-20T05:29:18.375317Z"},"trusted":true},"outputs":[],"source":["learn.show_results()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:00:44.780247Z","iopub.status.busy":"2023-11-20T05:00:44.779354Z","iopub.status.idle":"2023-11-20T05:00:48.150831Z","shell.execute_reply":"2023-11-20T05:00:48.149980Z","shell.execute_reply.started":"2023-11-20T05:00:44.780208Z"},"trusted":true},"outputs":[],"source":["# Save the model\n","learn.export(path/f'Liver_segmentation')"]},{"cell_type":"markdown","metadata":{},"source":["# **4- Testing the Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load saved model\n","if (GENERATE_JPG_FILES) :\n","    \n","    tfms = [Resize(IMAGE_SIZE), IntToFloatTensor(),Normalize()]\n","    learn0 = load_learner(path/f'Liver_segmentation',cpu=False )\n","    learn0.dls.transform = tfms"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def nii_tfm(fn,wins): \n","\n","    test_nii  = read_nii(fn)\n","    curr_dim  = test_nii.shape[2] # 512, 512, curr_dim\n","    slices = []\n","    \n","    for curr_slice in range(curr_dim):\n","        data = tensor(test_nii[...,curr_slice].astype(np.float32))\n","        data = (data.to_nchan(wins)*255).byte()\n","        slices.append(TensorImage(data))\n","                      \n","    return slices "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:30:00.881008Z","iopub.status.busy":"2023-11-20T05:30:00.880632Z","iopub.status.idle":"2023-11-20T05:30:05.533134Z","shell.execute_reply":"2023-11-20T05:30:05.532059Z","shell.execute_reply.started":"2023-11-20T05:30:00.880977Z"},"trusted":true},"outputs":[],"source":["tst = 20\n","\n","test_nii   = read_nii(df_files.loc[tst,'dirname']+\"/\"+df_files.loc[tst,'filename'])\n","test_mask  = read_nii(df_files.loc[tst,'mask_dirname']+\"/\"+df_files.loc[tst,'mask_filename'])\n","print(test_nii.shape)\n","\n","test_slice_idx = 500\n","\n","sample_slice = tensor(test_nii[...,test_slice_idx].astype(np.float32))\n","\n","plot_sample([test_nii[...,test_slice_idx], test_mask[...,test_slice_idx]])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:30:15.173101Z","iopub.status.busy":"2023-11-20T05:30:15.172713Z","iopub.status.idle":"2023-11-20T05:30:45.052967Z","shell.execute_reply":"2023-11-20T05:30:45.051919Z","shell.execute_reply.started":"2023-11-20T05:30:15.173068Z"},"trusted":true},"outputs":[],"source":["# Prepare a nii test file for prediction \n","\n","test_files = nii_tfm(df_files.loc[tst,'dirname']+\"/\"+df_files.loc[tst,'filename'],[dicom_windows.liver, dicom_windows.custom])\n","print(\"Number of test slices: \", len(test_files))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:30:49.499950Z","iopub.status.busy":"2023-11-20T05:30:49.498954Z","iopub.status.idle":"2023-11-20T05:30:49.758308Z","shell.execute_reply":"2023-11-20T05:30:49.757393Z","shell.execute_reply.started":"2023-11-20T05:30:49.499913Z"},"trusted":true},"outputs":[],"source":["# Check an input for a test file\n","show_image(test_files[test_slice_idx])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-20T05:30:56.294604Z","iopub.status.busy":"2023-11-20T05:30:56.294158Z","iopub.status.idle":"2023-11-20T05:31:08.323575Z","shell.execute_reply":"2023-11-20T05:31:08.322311Z","shell.execute_reply.started":"2023-11-20T05:30:56.294566Z"},"trusted":true},"outputs":[],"source":["# Get predictions for a Test file for volumetric analysis\n","\n","test_dl = learn0.dls.test_dl(test_files)\n","preds, y = learn0.get_preds(dl=test_dl)\n","\n","predicted_mask = np.argmax(preds, axis=1)\n","\n","plt.imshow(predicted_mask[test_slice_idx])"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":767686,"sourceId":1327578,"sourceType":"datasetVersion"},{"datasetId":769463,"sourceId":1327590,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
